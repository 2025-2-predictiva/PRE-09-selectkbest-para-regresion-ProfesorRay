"""Autogradingscript - Tests para SelectKBest en regresi√≥n."""

import pytest


def load_data():
    """
    Carga y preprocesa el dataset Auto MPG.
    
    Returns:
        tuple: (X, y) donde X son las caracter√≠sticas e y es el target MPG.
    """
    import pandas as pd

    dataset = pd.read_csv("files/input/auto_mpg.csv")
    dataset = dataset.dropna()  # Elimina las 6 filas con Horsepower NaN
    dataset["Origin"] = dataset["Origin"].map(
        {1: "USA", 2: "Europe", 3: "Japan"},
    )
    y = dataset.pop("MPG")
    x = dataset.copy()

    return x, y


def load_estimator():
    """
    Carga el estimador entrenado desde el archivo pickle.
    
    Returns:
        sklearn estimator: El estimador entrenado o None si no existe.
    """
    import os
    import pickle

    if not os.path.exists("homework/estimator.pickle"):
        return None
    with open("homework/estimator.pickle", "rb") as file:
        estimator = pickle.load(file)

    return estimator


# ============================================================================
# TESTS DE CALIDAD DE DATOS
# ============================================================================

def test_data_loading():
    """Test: Verificar que la carga de datos funciona correctamente."""
    x, y = load_data()
    
    # Verificar estructura b√°sica
    assert x.shape[0] == 392  # 398 originales - 6 NaN = 392
    assert x.shape[1] == 7   # 7 caracter√≠sticas despu√©s de quitar MPG
    assert len(y) == 392     # Target deber√≠a tener la misma longitud
    
    # Verificar que Origin se mape√≥ correctamente
    assert set(x["Origin"].unique()) <= {"USA", "Europe", "Japan"}
    
    # Verificar que no hay valores faltantes despu√©s del preprocesamiento
    assert x.isnull().sum().sum() == 0
    assert y.isnull().sum() == 0


def test_data_preprocessing():
    """Test: Verificar el preprocesamiento de datos."""
    x, y = load_data()
    
    # Verificar rangos de datos
    assert y.min() > 0      # MPG deber√≠a ser positivo
    assert y.max() < 50    # Valores realistas para MPG
    
    # Verificar caracter√≠sticas num√©ricas
    numeric_cols = ['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year']
    for col in numeric_cols:
        assert x[col].dtype in ['int64', 'float64']
        assert x[col].min() > 0


# ============================================================================
# TESTS DE MODELO
# ============================================================================

def test_estimator_availability():
    """Test: Verificar que el modelo entrenado existe."""
    estimator = load_estimator()
    assert estimator is not None, "No se encontr√≥ el modelo entrenado"
    
    # Verificar que es un estimador sklearn
    assert hasattr(estimator, 'predict')
    assert hasattr(estimator, 'best_estimator_')  # Deber√≠a ser GridSearchCV


def test_model_performance_minimum():
    """
    Test: Rendimiento m√≠nimo requerido.
    
    El modelo debe tener al menos un R¬≤ de 0.6 (60% de varianza explicada).
    """
    from sklearn.metrics import r2_score

    x, y = load_data()
    estimator = load_estimator()
    
    y_pred = estimator.predict(x)
    r2 = r2_score(y, y_pred)

    assert r2 > 0.6, f"Actor de correlaci√≥n R¬≤ {r2:.3f} es menor al m√≠nimo requerido 0.6"


def test_model_predictions_consistency():
    """Test: Verificar consistencia de las predicciones."""
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    import numpy as np

    x, y = load_data()
    estimator = load_estimator()
    
    y_pred = estimator.predict(x)
    
    # Verificar que las predicciones son valores num√©ricos v√°lidos
    assert np.all(np.isfinite(y_pred))  # No NaN ni infinitos
    assert np.all(y_pred >= 0)         # MPG no puede ser negativo
    
    # Verificar que MAE y MSE son razonables
    mae = mean_absolute_error(y, y_pred)
    mse = mean_squared_error(y, y_pred)
    
    assert mae < 10.0, f"‚ö†Ô∏è MAE {mae:.2f} es muy alto (revisar modelo)"
    assert mse < 200.0, f"‚ö†Ô∏è MSE {mse:.2f} es muy alto (revisar modelo)"


# ============================================================================
# TESTS DE CARACTER√çSTICAS SELECCIONADAS (SelectKBest)
# ============================================================================

def test_feature_selection():
    """
    Test: Verificar que SelectKBest est√° configurado correctamente.
    """
    estimator = load_estimator()
    
    # Verificar que el pipeline contiene SelectKBest
    pipeline = estimator.best_estimator_
    assert 'selectkbest' in pipeline.named_steps
    
    selectkbest = pipeline.named_steps['selectkbest']
    
    # Verificar que k es razonable (entre 1 y numero de features)
    x, y = load_data()
    max_features = x.shape[1]
    k = selectkbest.k
    
    assert 1 <= k <= max_features, f"K={k} debe estar entre 1 y {max_features}"
    
    # Verificar que SelecKBest usando f_regression
    from sklearn.feature_selection import f_regression
    assert selectkbest.get_params()['score_func'] == f_regression


def test_preprocessing_pipeline():
    """
    Test: Verificar que el pipeline de preprocesamiento es correcto.
    """
    estimator = load_estimator()
    pipeline = estimator.best_estimator_
    
    # Verificar ColumnTransformer para OneHotEncoder en Origin
    transformer = pipeline.named_steps['tranformer']  # Nota: hay typo en 'tranformer'
    assert hasattr(transformer, 'transformers')
    
    # Verificar que StandardScaler est√° en remainder
    assert transformer.remainder.__class__.__name__ == 'StandardScaler'


# ============================================================================
# TESTS DE VALIDACI√ìN CRUZADA Y OPTIMIZACI√ìN
# ============================================================================

def test_grid_search_optimization():
    """Test: Verificar que GridSearchCV se ejecut√≥ correctamente."""
    estimator = load_estimator()
    
    # Verificar que es GridSearchCV
    assert hasattr(estimator, 'best_estimator_')
    assert hasattr(estimator, 'best_params_')
    assert hasattr(estimator, 'cv_results_')
    
    # Verificar que se prob√≥ al menos diferentes valores de k
    best_params = estimator.best_params_
    assert 'selectkbest__k' in best_params
    
    # Verificar que se hizo validaci√≥n cruzada
    assert estimator.cv == 5


def test_reproducibility():
    """
    Test: Verificar que los resultados son reproducibles.
    """
    from sklearn.metrics import r2_score
    
    x, y = load_data()
    estimator = load_estimator()
    
    # Hacer predicciones m√∫ltiples veces
    y_pred_1 = estimator.predict(x)
    y_pred_2 = estimator.predict(x)
    
    # Los resultados deben ser id√©nticos
    import numpy as np
    assert np.array_equal(y_pred_1, y_pred_2), "Predicciones inconsistentes"
    
    # Los scores tambi√©n deben ser iguales
    r2_1 = r2_score(y, y_pred_1)
    r2_2 = r2_score(y, y_pred_2)
    assert r2_1 == r2_2, "Scores inconsistentes"


# ============================================================================
# TEST PRINCIPAL DE EVALUACI√ìN (ORIGINAL)
# ============================================================================

def test_01():
    """
    Test principal: Evaluaci√≥n del rendimiento del modelo.
    
    Este test verifica que el modelo implementado cumple con el rendimiento m√≠nimo
    requerido para SelectKBest en regresi√≥n.
    """
    from sklearn.metrics import r2_score

    x, y = load_data()
    estimator = load_estimator()
    
    y_pred = estimator.predict(x)
    r2 = r2_score(y, y_pred)

    print(f"\nüìä RESULTADOS DEL MODELO:")
    print(f"üè∑Ô∏è  Dataset: Auto MPG ({x.shape[0]} muestras, {x.shape[1]} caracter√≠sticas)")
    print(f"üéØ R¬≤ Score: {r2:.4f} ({r2*100:.1f}% de varianza explicada)")
    print(f"‚úÖ Test {'APROBADO' if r2 > 0.6 else 'REPROBADO'} - Umbral m√≠nimo: 0.6")

    assert r2 > 0.6